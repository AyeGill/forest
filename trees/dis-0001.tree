\title{Entropy: the chain rule in terms of monad algebras}
\author{david-spivak}
\date{2024-01-25}
\import{macros}

%To see the result, 
%1. type "./serve.sh" in the terminal
%2. type "./build.sh" in a new terminal.
%3. Go to http://localhost:8080/dis-0001.xml

\texpackage{tikz-cd,amssymb}

\p{Inspired by Vigneux's talk this morning, I was thinking a bit about Shannon's theorem on entropy. It says that (up to a constant multiple) Shannon entropy is the only continuous function #{S\colon \mathtt{lott}(1)\to\mathbb{R}_{\geq0}}, from the set of probability distributions on finite sets to the set of nonnegative reals that satisfies the chain rule. Here #{\mathtt{lott}} is the monad underlying what Leinster calls the operad of simplices; I wrote about it in this [Topos blog post](https://topos.site/blog/2023/03/the-distributions-monad-is-a-retract-of-the-lotteries-monad/). As an example of the chain rule, suppose #{P_1,P_2,P_3} are nonnegative reals such that #{P_1+P_2+P_3=1}. Then 
##{S(P_1,P_2,P_3)=S(P_1+P_2,P_3)+(P_1+P_2)S\left(\frac{P_1}{P_1+P_2},\frac{P_2}{P_1+P_2}\right)+P_3S(1).}
We can write out the general formula in Poly notation: an entropy function is any function #{S\colon\mathtt{lott}(1)\to\mathbb{R}_{\geq0}} satisfying the following two diagrams:}

\texfig{
\begin{tikzcd}
    1\ar[r, equal]\ar[d, "\eta\lhd 1"']&
    1\ar[d, "0"]\\
    \mathtt{lott}\lhd 1\ar[r, "S"']&
    \mathbb{R}_{\geq0}
\end{tikzcd}
\hspace{.6in}
\begin{tikzcd}
    \mathtt{lott}\lhd\mathtt{lott}\lhd 1
        \ar[d, "\mu"']
        \ar[r,"{(\mathtt{lott}\lhd!,\mathtt{lott}\lhd S)}"]&[30pt]
    (\mathtt{lott}\lhd 1)\times(\mathtt{lott}\lhd\mathbb{R}_{\geq0})
        \ar[r, "S\times\mathbb{E}"]&
    \mathbb{R}_{\geq0}\times \mathbb{R}_{\geq0}
        \ar[d, "+"]\\
    \mathtt{lott}\lhd 1\ar[rr, "S"']&&
    \mathbb{R}_{\geq0}
\end{tikzcd}
}
\p{Here, the map #{\mathbb{E}\colon\mathtt{lott}(\mathbb{R}_{\geq0})\to\mathbb{R}_{\geq0}} is the expected value of a distribution of real numbers.}

\p{This same definition, "the chain rule", makes sense for any monad #{(t,\eta,\mu)}, monoid #{M,e,*} and algebra structure #{h\colon t(M)\to M}. Now I don't know why, but part of me wants to insist that there is some coherence between these, as follows.}

\texfig{
\begin{tikzcd}
    1\ar[r, "\eta(e)"]\ar[d, "e"']&
    t(M)\ar[d, "h"]\\
    M\ar[r, equal]&
    M
\end{tikzcd}
\hspace{.6in}
\begin{tikzcd}
    t(M)\times t(M)\ar[d, "h\times h"']\ar[r, "Day"]&
    (t\otimes t)(M\times M)\ar[r, "{\mu(+)}"]&
    t(M)\ar[d, "h"]\\
    M\times M\ar[rr, "+"']&&
    M
\end{tikzcd}
}
\p{Here, #{\otimes} is the Day convolution of #{\times}, which in Poly is indeed denoted #{\otimes}, the map ``Day" comes from its universal property, and the map #{t\otimes t\to t\circ t}, implicit in calling #{\mu}, comes from duoidality.}

\p{So let's define an *entropy* on a monoidal #{t}-algebra #{t,M,h} to be a map #{S\colon t(1)\to M} making the following diagrams commute.}
\texfig{
\begin{tikzcd}
    1\ar[r, equal]\ar[d, "\eta\lhd 1"']&
    1\ar[d, "0"]\\
    t(1)\ar[r, "S"']&
    M
\end{tikzcd}
\hspace{.6in}
\begin{tikzcd}
    t\circ t(1)
        \ar[d, "\mu"']
        \ar[r,"{(t(!),t(S))}"]&[30pt]
    t(1)\times t(M)
        \ar[r, "S\times h"]&
    M\times M
        \ar[d, "*"]\\
    t(1)\ar[rr, "S"']&&
    M
\end{tikzcd}
}

\p{I don't know much about entropies for other monads and other monoids. The only entropy function for the identity monad is the monoid unit, #{e\colon 1\to M}. If #{t=y+1} is the Maybe monad, so that a #{t}-algebra is a pointed set, I think the coherence conditions say that the marked point of the monoid must be a null element, i.e. an element #{m_0} satisfying #{m*m_0=m_0=m_0*m} for all #{m}. And I think that an entropy in this case can be identified with any choice of element of #{M}. Please feel free to check me and let me know!}

\p{Anyway, I wonder if there are any monads with interesting notions of entropy.}